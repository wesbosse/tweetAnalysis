{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionable Tweet Classification\n",
    "\n",
    "\n",
    "### Binary Classification Using NLP\n",
    "\n",
    "Wesley Bosse, Oct. 30th\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "\n",
    "The number of tweets sent every second is estimated to be between 6-10k. When it comes to the moderation of these tweets, it would take extraordinary man power to judge by hand. A binary classification model that is tuned for correctly identifying questionable content could cut this work down tremendously. \n",
    "\n",
    "I am approaching this problem as someone building a proof of concept model for moderating tweets posted from a network of high-profile accounts. The goal will be to identify as many of the questionable tweets as possible, without engaging in a scorched earth policy. I will move end to end but not spend too much time in any one area. This way, I can hopefully come up with a decent working model with plenty of ideas as to how to iterate.\n",
    "\n",
    "### Data:\n",
    "\n",
    "I was provided with 22,000 labeled tweets, nearly 3000 of which were marked as questionable. \n",
    "\n",
    "DATA DICTIONARY:\n",
    " - `post_id` : an alphanumeric string that pertains to some post id, although it is not the original twitter id.\n",
    " - `text`: a string of the tweet content\n",
    " - `date_posted`: the timestamp on the tweet, as a string\n",
    " - `questionable_content`: a binary label for each tweet\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "There were 70 tweets missing their text, which were dropped. The Snowball and Porter Stemmers were tested throughout the process, as well as the Word Net Lemmatizer.\n",
    "\n",
    "The cleaning that needs to be done:\n",
    "    - Cleaning up retweets, mentions\n",
    "    - Removing numbers\n",
    "    - Removing non-english text\n",
    "    \n",
    "There were several performance bottle necks in this notebook, one of which I believe could be solved by using hashing vectorizer, especially if this process was applied to a larger data set.\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "The code file [here]()\n",
    "\n",
    "During my EDA, I completed the following steps:\n",
    "    - Check target class balance/data set size\n",
    "    - Clean up missing data\n",
    "    - Re-format and Investigate `date_posted` column\n",
    "    - CountVectorize and Model as EDA: look and unigrams to see what words are important to off the shelf classification\n",
    "    - dig for words by eliminating features via Stemming/Lemmatizing\n",
    "    - Plot ROC curve to investigate how probability thresholds could be leveraged\n",
    "\n",
    "The EDA models had good accuracies, but recall scores were hovering around 57%. Keeping in mind the context under which we are operating, we are more concerned with optimizing recall than accuracy. Because of this, and for the sake of performance, I will under-sample the data before feature engineering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "The code file  [here]()\n",
    "\n",
    "As far as the important features, visual inspection revealed that common curse words, racial slurs, and sexually explicit phrases all were heavy indicators of questionable content. I would like to build separate lists of words to create features based on the detection of each kind of questionable content, but for the sake of time I used a word list found online/aggregated from words in the EDA results. The list was used to create one single `contains_nsfw` column. To reduce collinearity/allow the model to dig deeper, I also removed the flagged columns from the data set once rows have been labeled with the `contains_nsfw` label.\n",
    "\n",
    "\n",
    "Some low hanging fruit to include were the VADER polarity scores, which include positive, neutral, negative, and compound polarity scores. Sentiment could be used for interaction terms with the presence of certain vocab, but further work is required to come up with a solid implementation of that. \n",
    "\n",
    "\n",
    "### Modeling\n",
    "\n",
    "The code file [here]()\n",
    "\n",
    "Based on the EDA and initial performance tests, I stuck with the AdaBoostClassifier. I gridsearched over a few base estimators, n_estimators, etc. \n",
    "\n",
    "\n",
    "### Model Performance \n",
    "Better logging of metrics is definitely on the to-do list. Base recall started around .54 - .57, undersampling brought us above .6, and our final grid search gave us a recall of ~.72.\n",
    "\n",
    "With a test set of 1225 tweets from the undersampled set, I am still predicting over 200 false negatives and 100 false positives. Clearly there is room to do better. \n",
    "\n",
    "### Pipeline (Attempt)\n",
    "\n",
    "I attempted to create a pipeline but wrecked it when I was refactoring. I will fix it soon, but wanted to submit this report before. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "\n",
    "- More cleaning! numbers, non-english, etc. \n",
    "- Examples of word lists to incorporate:\n",
    "    - https://en.wikipedia.org/wiki/Category:Ethnic_and_religious_slurs\n",
    "    - https://en.wikipedia.org/wiki/Category:Sexuality_and_gender-related_slurs\n",
    "- Fix Pipeline\n",
    "- Interaction terms with sentiment.\n",
    "- Dimensionality reduction\n",
    "- higher ngram ranges with hashing vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
